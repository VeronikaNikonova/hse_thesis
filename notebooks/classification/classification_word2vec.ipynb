{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bad98bFFKMgX",
        "outputId": "5608a627-91a5-4d4e-d7ec-1d33d5d927c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Ol_CMYdIKaiM",
        "outputId": "a190a665-fd19-4d80-99ad-e8ef6f1fe19f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           WORD  BASE_YEAR  GROUND_TRUTH  NEXT_YEAR\n",
              "0      железный       2006             0       2007\n",
              "1     подземный       2009             1       2010\n",
              "2     катарский       2003             1       2004\n",
              "3  гуманитарный       2005             0       2006\n",
              "4   капитальный       2012             0       2013"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3c374a6-b6de-4566-9429-2b0aded46f8f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>WORD</th>\n",
              "      <th>BASE_YEAR</th>\n",
              "      <th>GROUND_TRUTH</th>\n",
              "      <th>NEXT_YEAR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>железный</td>\n",
              "      <td>2006</td>\n",
              "      <td>0</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>подземный</td>\n",
              "      <td>2009</td>\n",
              "      <td>1</td>\n",
              "      <td>2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>катарский</td>\n",
              "      <td>2003</td>\n",
              "      <td>1</td>\n",
              "      <td>2004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>гуманитарный</td>\n",
              "      <td>2005</td>\n",
              "      <td>0</td>\n",
              "      <td>2006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>капитальный</td>\n",
              "      <td>2012</td>\n",
              "      <td>0</td>\n",
              "      <td>2013</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3c374a6-b6de-4566-9429-2b0aded46f8f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3c374a6-b6de-4566-9429-2b0aded46f8f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3c374a6-b6de-4566-9429-2b0aded46f8f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_words = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/Thesis/Data/Classification/Common/classification_words.csv')\n",
        "df_words.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KiFyeEIcLy3G"
      },
      "outputs": [],
      "source": [
        "# Source: https://gist.github.com/zhicongchen/9e23d5c3f1e5b1293b16133485cd17d8\n",
        "import gensim\n",
        "import numpy as np\n",
        "\n",
        "def smart_procrustes_align_gensim(base_embed, other_embed, words=None):\n",
        "    \"\"\"\n",
        "    Original script: https://gist.github.com/quadrismegistus/09a93e219a6ffc4f216fb85235535faf\n",
        "    Procrustes align two gensim word2vec models (to allow for comparison between same word across models).\n",
        "    Code ported from HistWords <https://github.com/williamleif/histwords> by William Hamilton <wleif@stanford.edu>.\n",
        "        \n",
        "    First, intersect the vocabularies (see `intersection_align_gensim` documentation).\n",
        "    Then do the alignment on the other_embed model.\n",
        "    Replace the other_embed model's syn0 and syn0norm numpy matrices with the aligned version.\n",
        "    Return other_embed.\n",
        "    If `words` is set, intersect the two models' vocabulary with the vocabulary in words (see `intersection_align_gensim` documentation).\n",
        "    \"\"\"\n",
        "\n",
        "    # patch by Richard So [https://twitter.com/richardjeanso) (thanks!) to update this code for new version of gensim\n",
        "    # base_embed.init_sims(replace=True)\n",
        "    # other_embed.init_sims(replace=True)\n",
        "\n",
        "    # make sure vocabulary and indices are aligned\n",
        "    in_base_embed, in_other_embed = intersection_align_gensim(base_embed, other_embed, words=words)\n",
        "\n",
        "    # get the (normalized) embedding matrices\n",
        "    base_vecs = in_base_embed.wv.get_normed_vectors()\n",
        "    other_vecs = in_other_embed.wv.get_normed_vectors()\n",
        "\n",
        "    # just a matrix dot product with numpy\n",
        "    m = other_vecs.T.dot(base_vecs) \n",
        "    # SVD method from numpy\n",
        "    u, _, v = np.linalg.svd(m)\n",
        "    # another matrix operation\n",
        "    ortho = u.dot(v) \n",
        "    # Replace original array with modified one, i.e. multiplying the embedding matrix by \"ortho\"\n",
        "    other_embed.wv.vectors = (other_embed.wv.vectors).dot(ortho)    \n",
        "    \n",
        "    return other_embed\n",
        "\n",
        "def intersection_align_gensim(m1, m2, words=None):\n",
        "    \"\"\"\n",
        "    Intersect two gensim word2vec models, m1 and m2.\n",
        "    Only the shared vocabulary between them is kept.\n",
        "    If 'words' is set (as list or set), then the vocabulary is intersected with this list as well.\n",
        "    Indices are re-organized from 0..N in order of descending frequency (=sum of counts from both m1 and m2).\n",
        "    These indices correspond to the new syn0 and syn0norm objects in both gensim models:\n",
        "        -- so that Row 0 of m1.syn0 will be for the same word as Row 0 of m2.syn0\n",
        "        -- you can find the index of any word on the .index2word list: model.index2word.index(word) => 2\n",
        "    The .vocab dictionary is also updated for each model, preserving the count but updating the index.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the vocab for each model\n",
        "    vocab_m1 = set(m1.wv.index_to_key)\n",
        "    vocab_m2 = set(m2.wv.index_to_key)\n",
        "\n",
        "    # Find the common vocabulary\n",
        "    common_vocab = vocab_m1 & vocab_m2\n",
        "    if words: common_vocab &= set(words)\n",
        "\n",
        "    # If no alignment necessary because vocab is identical...\n",
        "    if not vocab_m1 - common_vocab and not vocab_m2 - common_vocab:\n",
        "        return (m1,m2)\n",
        "\n",
        "    # Otherwise sort by frequency (summed for both)\n",
        "    common_vocab = list(common_vocab)\n",
        "    common_vocab.sort(key=lambda w: m1.wv.get_vecattr(w, \"count\") + m2.wv.get_vecattr(w, \"count\"), reverse=True)\n",
        "    # print(len(common_vocab))\n",
        "\n",
        "    # Then for each model...\n",
        "    for m in [m1, m2]:\n",
        "        # Replace old syn0norm array with new one (with common vocab)\n",
        "        indices = [m.wv.key_to_index[w] for w in common_vocab]\n",
        "        old_arr = m.wv.vectors\n",
        "        new_arr = np.array([old_arr[index] for index in indices])\n",
        "        m.wv.vectors = new_arr\n",
        "\n",
        "        # Replace old vocab dictionary with new one (with common vocab)\n",
        "        # and old index2word with new one\n",
        "        new_key_to_index = {}\n",
        "        new_index_to_key = []\n",
        "        for new_index, key in enumerate(common_vocab):\n",
        "            new_key_to_index[key] = new_index\n",
        "            new_index_to_key.append(key)\n",
        "        m.wv.key_to_index = new_key_to_index\n",
        "        m.wv.index_to_key = new_index_to_key\n",
        "        \n",
        "        print(len(m.wv.key_to_index), len(m.wv.vectors))\n",
        "        \n",
        "    return (m1,m2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jPAYcYWSoHc",
        "outputId": "c06c0e3f-cbee-4866-87d6-5c163f66a097"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 14/14 [1:51:57<00:00, 479.85s/it]\n"
          ]
        }
      ],
      "source": [
        "from ast import literal_eval\n",
        "\n",
        "# train new models with window size 10 and minimum frequency 5\n",
        "years = [i for i in range(2000, 2015)]\n",
        "for year in tqdm(years):\n",
        "    df_temp = pd.read_csv(f'/content/gdrive/MyDrive/Colab Notebooks/Thesis/Data/Common/News/data_{year}.csv', compression='zip',\n",
        "                   converters={'tokenized_text': literal_eval, 'lemmas': literal_eval})\n",
        "    model = Word2Vec(sentences=df_temp.lemmas, vector_size=300, window=10, min_count=5, \n",
        "                     sg=1, negative=5, ns_exponent=0.75, workers=4)\n",
        "    model.save(f'/content/gdrive/MyDrive/Colab Notebooks/Thesis/Models/Classification/Word2vec/word2vec_5w10_{year}.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "t7PWKEYgH2dQ"
      },
      "outputs": [],
      "source": [
        "df_words['cos_similarity_w2v'] = [0 for i in range(df_words.shape[0])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8OycNEuL9zF",
        "outputId": "c3546a35-4f9c-4b4b-9b10-a71e95aff189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 1/14 [00:04<00:56,  4.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15229 15229\n",
            "15229 15229\n",
            "подавляющий not present\n",
            "летный not present\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 2/14 [00:06<00:33,  2.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17266 17266\n",
            "17266 17266\n",
            "приемный not present\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 3/14 [00:08<00:29,  2.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17453 17453\n",
            "17453 17453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 4/14 [00:10<00:23,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18348 18348\n",
            "18348 18348\n",
            "южноуральский not present\n",
            "уставной not present\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 5/14 [00:12<00:19,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20502 20502\n",
            "20502 20502\n",
            "приемный not present\n",
            "мертвый not present\n",
            "22745 22745\n",
            "22745 22745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 6/14 [00:14<00:17,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "приемный not present\n",
            "23298 23298\n",
            "23298 23298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 7/14 [00:16<00:15,  2.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "подавляющий not present\n",
            "24837 24837\n",
            "24837 24837\n",
            "приемный not present"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 8/14 [00:20<00:16,  2.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "27672 27672\n",
            "27672 27672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 9/14 [00:24<00:16,  3.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "саяно-шушенский not present\n",
            "принятый not present\n",
            "молодежный not present\n",
            "28193 28193\n",
            "28193 28193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 10/14 [00:29<00:13,  3.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "саяно-шушенский not present\n",
            "27638 27638\n",
            "27638 27638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▊  | 11/14 [00:34<00:12,  4.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "съемочный not present\n",
            "28310 28310\n",
            "28310 28310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 12/14 [00:39<00:09,  4.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29303 29303\n",
            "29303 29303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 13/14 [00:44<00:04,  4.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "приемный not present\n",
            "принятый not present\n",
            "27109 27109\n",
            "27109 27109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14/14 [00:47<00:00,  3.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "приемный not present\n",
            "санкт-петербургский not present\n",
            "самопровозглашенный not present\n",
            "надежный not present\n",
            "21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "\n",
        "years = [i for i in range(2000, 2014)]\n",
        "\n",
        "count = 0\n",
        "\n",
        "for year in tqdm(years):\n",
        "    model_0 = Word2Vec.load(f'/content/gdrive/MyDrive/Colab Notebooks/Thesis/Models/Classification/Word2vec/word2vec_5w10_{year}.model')\n",
        "    model_1 = Word2Vec.load(f'/content/gdrive/MyDrive/Colab Notebooks/Thesis/Models/Classification/Word2vec/word2vec_5w10_{year + 1}.model')   \n",
        "    m_1, m_0 = intersection_align_gensim(model_1, model_0)\n",
        "    m_0_modified = smart_procrustes_align_gensim(m_1, m_0)\n",
        "    \n",
        "    for i in df_words[df_words.BASE_YEAR == year].index:\n",
        "        word = df_words.WORD[i]\n",
        "        try:\n",
        "            df_words.loc[i, ('cos_similarity_w2v')] = cosine_similarity([m_0_modified.wv[word]], \n",
        "                                                                  [model_1.wv[word]])[0][0]\n",
        "        except:\n",
        "            print(f'{word} not present')\n",
        "            count += 1\n",
        "\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-JBONpWLEYD",
        "outputId": "105dbbf6-4f92-4ac2-ec8e-ccb6f8573d9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "280"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_words.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3hzUe3WGpJW",
        "outputId": "4bcd5a3d-4e69-47e7-887d-d1e8836307a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    220\n",
              "1     42\n",
              "2     18\n",
              "Name: GROUND_TRUTH, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df_words.GROUND_TRUTH.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7WggU5lFGyBp"
      },
      "outputs": [],
      "source": [
        "df_words_1 = df_words.drop(df_words[df_words.cos_similarity_w2v == 0].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PHf7zZ3Gugi",
        "outputId": "d8b72ad9-bc6b-401a-d39a-5395096b6e13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    203\n",
              "1     41\n",
              "2     15\n",
              "Name: GROUND_TRUTH, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df_words_1.GROUND_TRUTH.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_words_1.to_csv('/content/gdrive/MyDrive/Colab Notebooks/thesis/Data/Classification/Word2vec/df_cos_w2v.csv', index=False)"
      ],
      "metadata": {
        "id": "dqYTp42Wcjt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qmRtPVUATt1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "308c15d4-4de7-4777-c89b-d35beb4b3e27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5it [00:01,  4.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean F1 score: 0.4512\n",
            "Mean balanced accuracy score: 0.4811\n",
            "Mean precision score: 0.4418\n",
            "Mean recall score: 0.4811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score, balanced_accuracy_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "rfc_w2v = RandomForestClassifier(n_estimators=120, min_samples_split=4, random_state=42, class_weight='balanced', max_depth=4)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "f1_scores = []\n",
        "balanced_accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "\n",
        "for train_index, test_index in tqdm(skf.split(df_words_1.cos_similarity_w2v, df_words_1.GROUND_TRUTH)):\n",
        "    x_train_fold, x_test_fold = df_words_1.cos_similarity_w2v.iloc[train_index], df_words_1.cos_similarity_w2v.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = df_words_1.GROUND_TRUTH.iloc[train_index], df_words_1.GROUND_TRUTH.iloc[test_index]\n",
        "    rfc_w2v.fit(np.expand_dims(np.array(x_train_fold), axis=1), y_train_fold)\n",
        "    pred = rfc_w2v.predict(np.expand_dims(np.array(x_test_fold), axis=1))\n",
        "    f1_scores.append(f1_score(y_test_fold, pred, average='macro'))\n",
        "    balanced_accuracy_scores.append(balanced_accuracy_score(y_test_fold, pred))\n",
        "    precision_scores.append(precision_score(y_test_fold, pred, average='macro'))\n",
        "    recall_scores.append(recall_score(y_test_fold, pred, average='macro'))\n",
        "\n",
        "print(f'Mean F1 score: {np.mean(f1_scores):.4f}')\n",
        "print(f'Mean balanced accuracy score: {np.mean(balanced_accuracy_scores):.4f}')\n",
        "print(f'Mean precision score: {np.mean(precision_scores):.4f}')\n",
        "print(f'Mean recall score: {np.mean(recall_scores):.4f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}