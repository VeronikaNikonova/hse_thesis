# Discovering semantic shifts in the Russian language in news and social media using word embedding models

This research is focused on discovering and detecting diachronic semantic shifts in the Russian language with the use of different word embedding models that represent different approaches: 
<l>1) static approach (Skip-gram with negative sampling model),</l> 
<l>2) dynamic approach (Dynamic word embeddings model) and </l> 
<l>3) contextualized approach (BERT model).</l> <br>
We apply the indicated models to the News corpus and to the Social media corpus in order to reveal social, political, cultural, etc. changes through semantic changes that are assessed as the similarity (namely, cosine similarity) between embeddings of a word in different time slices (from 2000 to 2019 and from 2007 to 2019 correspondingly).<br>
We analyze the revealed changes and compare performance of the models on two tasks: 1) discovering semantic shifts and 2) detecting known shifts.<br>

